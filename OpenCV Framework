#import and open an image

import cv2
print("Package Imported")

img = cv2.imread("Resources/Lena.png")

cv2.imshow("Output", img)
cv2.waitKey(0)

#import and open video (ending if q is pressed)

import cv2

cap = cv2.VideoCapture("Resources/video.mp4")

while True:
    success, img = cap.read()
    cv2.imshow("Video", img)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
        
#open a video from webcam

import cv2

cap = cv2.VideoCapture(0)
#width size
cap.set(3,640)
#hight size
cap.set(4,480)
#changing the brightness
cap.set(10,100)
while True:
    success, img = cap.read()
    cv2.imshow("Video", img)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
        
        


#mixing photos and videos

import cv2
import numpy as np
img = cv2.imread("Resources/Jula.jpg")
#increase gray color of the picture
imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
#increase blur
imgBlur = cv2.GaussianBlur(imgGray,(7,7),0)
imgCanny = cv2.Canny(img, 30, 50)
kernel = np.ones((5,5),np.uint8)
imgDialation = cv2.dilate(imgCanny,kernel,iterations=1)
imgEroded = cv2.erode(imgDialation,kernel,iterations=1)

cv2.imshow("Gray Image", imgGray)
cv2.imshow("Blur Image", imgBlur)
cv2.imshow("Canny image", imgCanny)
cv2.imshow("Dialation Image", imgDialation)
cv2.imshow("Dialation Image", imgEroded)
cv2.waitKey(0)



#resize images and corners

import cv2
import numpy as np

img = cv2.imread("Resources/Jula.jpg")
#show height, width and number of channel RGB
print(img.shape)
#resize the image
imgResize = cv2.resize(img, (300,200))
imgCropped = img[0:200,200:500]
cv2.imshow("Image",img)
cv2.imshow("Image Resize",imgResize)
cv2.imshow("Image Cropped",imgCropped)
cv2.waitKey(0)



#drawing objects and writing on image

import cv2
import numpy as np

#zeros means black, size of our matrix
img = np.zeros((512,512,3),np.uint8)
print(img)
#limits the range height, width
img[200:300,100:300] = 255,0,0
#line through all image area
cv2.line(img,(0,0),(img.shape[1],img.shape[0]),(0,500,0),3)
#making rectangle
cv2.rectangle(img,(0,0),(250,350),(0,0,255),2) #or cv2.FILLED to fill the rectangle
#drawing rectangle
cv2.circle(img,(400,50),30,(255,255,0),5)
#define text and fonts, scale, color and thickness
cv2.putText(img," OPENCV ",(300,200),cv2.FONT_HERSHEY_COMPLEX,1,(0,150,0),1)
print(img.shape)
cv2.imshow("Image",img)

cv2.waitKey(0)


#płaska perspektywa bazująca na kilku punktach

import cv2
import numpy as np
#making warp perspective (płaska)
img = cv2.imread("Resources/Jula.jpg")
#tick 3 points
pts1 = np.float32([[111,219],[287,188],[154,482],[352,440]])
width, height = 250,350
pts2 = np.float32([[0,0],[width,0],[0,height],[width,height]])
matrix = cv2.getPerspectiveTransform(pts1,pts2)

imgOutput = cv2.warpPerspective(img,matrix,(width,height))


cv2.imshow("Image",img)
cv2.imshow("Image Output",imgOutput)
cv2.waitKey(0)





#joining images together

img = cv2.imread('Resources/Jula.jpg')

#horizontal view
hor = np.hstack((img,img))
cv2.imshow("Horizontal",hor)

#vertical view
ver = np.vstack((img,img))
cv2.imshow("Vertical",ver)

cv2.waitKey(0)






import cv2
import numpy as np
#detecting colors
def empty(a):
    pass

path = 'Resources/Jula.jpg'
cv2.namedWindow("TrackBars")
cv2.resizeWindow("TrackBars",640,240)
cv2.createTrackbar("Hue Min","TrackBars",0,179,empty)
cv2.createTrackbar("Hue Max","TrackBars",179,179,empty)
cv2.createTrackbar("Sat Min","TrackBars",0,255,empty)
cv2.createTrackbar("Sat Max","TrackBars",255,255,empty)
cv2.createTrackbar("Val Min","TrackBars",0,255,empty)
cv2.createTrackbar("Val Max","TrackBars",255,255,empty)
while True:
      img = cv2.imread(path)
      #filtering colour range
      imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)
      h_min = cv2.getTrackbarPos("Hue Min","TrackBars")
      h_max = cv2.getTrackbarPos("Hue Max","TrackBars")
      s_min = cv2.getTrackbarPos("Sat Min","TrackBars")
      s_max = cv2.getTrackbarPos("Sat Max","TrackBars")
      v_min = cv2.getTrackbarPos("Val Min","TrackBars")
      v_max = cv2.getTrackbarPos("Val Max","TrackBars")
      print(h_min,h_max,s_min,s_max,v_min,v_max)
      lower = np.array([h_min,s_min,v_min])
      upper = np.array([h_max,s_max,v_max])
      mask = cv2.inRange(imgHSV, lower, upper)
      #kolorowanie wyodrębnionej przestrzeni 
      imgResult = cv2.bitwise_and(img,img,mask=mask)

      cv2.imshow("Original",img)
      cv2.imshow("HSV",imgHSV)
      cv2.imshow("imgResult",imgResult)

      cv2.waitKey(1)


#detecting figures

import cv2
import numpy as np
#contours and shapes detection


def getContours(img):
      contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)
      for cnt in contours:
            area = cv2.contourArea(cnt)
            print(area)
            cv2.drawContours(imgContour,cnt,-1,(255,0,0),2)
            if area > 1500 :
                  cv2.drawContours(imgContour, cnt, -1, (255, 0, 0), 3)
                  peri = cv2.arcLength(cnt,True)
                  print(peri)
                  #numbers of corners
                  approx = cv2.approxPolyDP(cnt,0.02*peri,True)
                  print(len(approx))
                  objCor = len(approx)
                  x , y, w, h = cv2.boundingRect(approx)

                  if objCor == 3:
                        objectType = "Trójkąt"
                  elif objCor == 4:
                        aspRatio = w/float(h)
                        if aspRatio > 0.95 and aspRatio < 1.05: objectType = "Kwadrat"
                        else: objectType = "Prostokąt"
                  elif objCor > 4: objectType = "Kolo"
                  else: objectType = "None"
                  #bounding boxes of each shapes that's detected
                  cv2.rectangle(imgContour, (x,y),(x+w,y+h),(0,255,0),2)
                  cv2.putText(imgContour,objectType,
                              (x+(w//2)-10,y+(h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.7,
                              (0,0,0),2)


path = 'Resources/figury.png'
img = cv2.imread(path)
imgContour = img.copy()

imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
imgBlur = cv2.GaussianBlur(imgGray,(7,7),1)
imgCanny = cv2.Canny(imgBlur,50,50)
getContours(imgCanny)

#finding contours
cv2.imshow("Gray",imgGray)
cv2.imshow("Blur",imgBlur)
cv2.imshow("Canny",imgCanny)
cv2.imshow("Contour",imgContour)

cv2.waitKey(0)




#face detection

import cv2
import numpy as np

#face detection

#create Cascade
faceCascade = cv2.CascadeClassifier("Resources/haarcascade_frontalface_default.xml")
img = cv2.imread('Resources/dziewczynki.jpg')
imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

faces = faceCascade.detectMultiScale(imgGray,1.1,2)
#bounding box around object that we have detected
for (x,y,w,h) in faces:
      cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)



cv2.imshow("Result", img)
cv2.waitKey(0)





#Project #1


import cv2
import numpy as np

#Project 1 Virtual Paint

#Read webcam
cap = cv2.VideoCapture(0)
#width size
cap.set(3,640)
#hight size
cap.set(4,480)
#changing the brightness
cap.set(10,150)

myColors = [[5,107,0,19,255,255],
            [133,56,0,159,156,255],
            [57,76,0,100,255,255]]
myColorValues = [[51,153,255],           #BGR
                  [255,0,255],
                  [0,255,0]]

myPoints = [] #[x, y, colorID]

def findColor(img,myColors,myColorValues):
      imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
      count = 0
      newPoints = []
      for color in myColors:
         lower = np.array(color[0:3])
         upper = np.array(color[3:6])
         mask = cv2.inRange(imgHSV, lower, upper)
         x,y = getContours(mask)
         cv2.circle(imgResult,(x,y),10,myColorValues[count],cv2.FILLED)
         if x != 0 and y != 0:
               newPoints.append([x,y,count])
         count += 1
         #cv2.imshow(str(color[0]),mask)
      return newPoints

def getContours(img):
      contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)
      x,y,w,h = 0,0,0,0
      for cnt in contours:
            area = cv2.contourArea(cnt)
            if area > 500 :
                  #cv2.drawContours(imgResult, cnt, -1, (255, 0, 0), 3)
                  peri = cv2.arcLength(cnt,True)
                  approx = cv2.approxPolyDP(cnt,0.02*peri,True)
                  x , y, w, h = cv2.boundingRect(approx)
      return x+w//2,y

def drawOnCanvas(myPoints, myColorValues):
      for point in myPoints:
            cv2.circle(imgResult, (point[0], point[1]), 10, myColorValues[point[2]], cv2.FILLED)


while True:
    success, img = cap.read()
    imgResult = img.copy()
    newPoints = findColor(img, myColors,myColorValues)
    if len(newPoints) != 0:
          for newP in newPoints:
                myPoints.append(newP)
    if len(myPoints)!=0:
          drawOnCanvas(myPoints,myColorValues)


    cv2.imshow("Result", imgResult)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
        
        
        




#Project #2 Scanner


 import cv2
import numpy as np
import numpy as np
########################################
widthImg=480
heightImg =640
########################################

#Read webcam
cap = cv2.VideoCapture(0)
#width size
cap.set(3,widthImg)
#hight size
cap.set(4,heightImg)
#changing the brightness
cap.set(10,150)

def preProcessing(img):
      imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
      imgBlur = cv2.GaussianBlur(imgGray, (5,5),1)
      imgCanny = cv2.Canny(imgBlur, 200, 200)
      kernel = np.ones((5,5))
      imgDial = cv2.dilate(imgCanny, kernel, iterations = 2)
      imgThres = cv2.erode(imgDial, kernel, iterations=1)

      return imgThres

#finding the biggest contours
def getContours(img):
      biggest = np.array([])
      contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)
      for cnt in contours:
            area = cv2.contourArea(cnt)
            cv2.drawContours(imgContour,cnt,-1,(255,0,0),2)
            if area > 5000 :
                  cv2.drawContours(imgContour, cnt, -1, (255, 0, 0), 3)
                  peri = cv2.arcLength(cnt,True)
                  #numbers of corners
                  approx = cv2.approxPolyDP(cnt,0.02*peri,True)
                  if area > maxArea and len(approx) == 4:
                        biggest = approx
                        maxArea = area
      cv2.drawContours(imgContour, biggest, -1, (255,0,0), 20) #drawing 4 corner points
      return biggest


def reorder (myPoints):
      myPoints = myPoints.reshape((4,2))
      myPointsNew = np.zeros((4,1,2),np.int32)
      add = myPoints.sum(1)
      #print("add,", add)

      myPointsNew[0] = myPoints[np.argmin(add)]
      myPointsNew[3] = myPoints[np.argmax(add)]
      diff = np.diff(myPoints,axis=1)
      myPointsNew[1] = myPoints[np.argmin(diff)]
      myPointsNew[2] = myPoints[np.argmax(diff)]
      #print("NewPoints", myPointsNew)
      return myPointsNew


def getWarp(img,biggest):
      biggest = reorder(biggest)
      print(biggest)
      pts1 = np.float32(biggest)
      pts2 = np.float32([[0, 0], [widthImg, 0], [0, heightImg], [widthImg, heightImg]])
      matrix = cv2.getPerspectiveTransform(pts1, pts2)
      imgOutput = cv2.warpPerspective(img, matrix, (widthImg, heightImg))

      imgCropped = imgOutput[20:imgOutput.shape[0]-20,20:imgOutput.shape[1]-20]
      imgCropped = cv2.resize(imgCropped,(widthImg,heightImg))


      return imgCropped



while True:
      success, img = cap.read()
      cv2.resize(img,(widthImg,heightImg))
      imgContour = img.copy()
      imgThres = preProcessing(img)
      biggest = getContours(imgThres)
      #print(biggest)


      imgWarped=getWarp(img,biggest)


      cv2.imshow("Result", imgWarped)
      if cv2.waitKey(1) & 0xFF == ord('q'):
            break

#Project 3 Plate detection

import cv2

cap = cv2.VideoCapture(0)
#width size
cap.set(3,640)
#hight size
cap.set(4,480)
#changing the brightness
cap.set(10,100)
count = 0
nPlateCascade = cv2.CascadeClassifier("Resources/haarcascade_russian_plate_number.xml")
minArea = 500
color=(255,0,255)
while True:
    success, img = cap.read()
    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    numberPlates = nPlateCascade.detectMultiScale(imgGray, 1.1, 4)
    # bounding box around object that we have detected
    for (x, y, w, h) in numberPlates:
          area = w*h
          if area > minArea:
                 cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 2)
                 cv2.putText(img, "Number Plate",(x,y-5),
                             cv2.FONT_HERSHEY_COMPLEX_SMALL,1,color,2)
                 imgRoi = img[y:y+h,x:x+w]
                 cv2.imshow("ROI",imgRoi)
    cv2.imshow("Video", img)
    if cv2.waitKey(1) & 0xFF == ord('s'):
          cv2.imwrite("Resources/Scanned/NoPlate_"+str(count)+".jpg",imgRoi)
          cv2.rectangle(img, (0, 200),(640,300),(0,255,0),cv2.FILLED)
          cv2.putText(img, "Scan Saved",(150,265),cv2.FONT_HERSHEY_DUPLEX,
                      2,(0,0,255),2)
          cv2.imshow("Result",img)
          cv2.waitKey(500)
          count += 1
        break

#Project 4 Frontal face and eyes detection


import cv2
import numpy as np

face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')

cap = cv2.VideoCapture(0)

while True:
      ret, img = cap.read()
      gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
      faces = face_cascade.detectMultiScale(gray)
      for (x,y,w,h) in faces:
            cv2.rectangle(img, (x,y),(x+w, y+h), (255,0,0), 2)
            roi_gray = gray[y:y+h, x:x+w]
            roi_color = img[y:y+h, x:x+w]
            eyes= eye_cascade.detectMultiScale(roi_gray)
            for (ex,ey, ew,eh) in eyes:
                  cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh),(0,255,0), 2)\

      cv2.imshow('img',img)
      k = cv2.waitKey(30) & 0xFF
      if k == 27:
            break
cap.release()
cv2.destroyAllWindows()
